# Sistema de Seguimiento de Env√≠os ‚Äî 99minutos

API REST orientada a eventos para el seguimiento en tiempo real de env√≠os log√≠sticos. Construida con Go 1.25 y Echo v4, dise√±ada para procesar m√°s de 10,000 eventos por segundo con ordenamiento garantizado por env√≠o e idempotencia nativa.

---

## Tabla de contenidos

1. [Descripci√≥n general](#descripci√≥n-general)
2. [Arquitectura](#arquitectura)
3. [Stack tecnol√≥gico](#stack-tecnol√≥gico)
4. [Decisiones de dise√±o](#decisiones-de-dise√±o)
5. [Inicio r√°pido](#-inicio-r√°pido)
6. [Documentaci√≥n de la API](#-documentaci√≥n-de-la-api)
7. [Pruebas](#pruebas)
8. [Observabilidad](#-observabilidad)
9. [Escalabilidad](#escalabilidad)
10. [Trade-offs y consideraciones de producci√≥n](#trade-offs-y-consideraciones-de-producci√≥n)
11. [Estructura del proyecto](#estructura-del-proyecto)
12. [Comandos de desarrollo](#comandos-de-desarrollo)
13. [Licencia](#licencia)

---

## Descripci√≥n general

Sistema de seguimiento de env√≠os para una empresa de log√≠stica latinoamericana. Permite:

- Registrar env√≠os con n√∫meros de rastreo √∫nicos en formato `99M-<8-char>`
- Recibir actualizaciones de estado en tiempo real desde m√∫ltiples fuentes (choferes, bodegas, esc√°neres)
- Mantener un historial de auditor√≠a completo por env√≠o
- Exponer una REST API segura con control de acceso basado en roles (RBAC)
- Procesar alta concurrencia con target de 10,000+ eventos por segundo

---

## Arquitectura

### Diagrama de alto nivel

<img src="./docs/higth-level-architecture-shipments.svg" alt="Diagrama de arquitectura" width="800"/>

### Clean Architecture ‚Äî tres capas

```
internal/domain/          ‚Üê Entidades de negocio y m√°quina de estados (sin dependencias externas)
internal/application/     ‚Üê Casos de uso y DTOs (depende solo del dominio)
internal/infrastructure/  ‚Üê Handlers HTTP, MongoDB, Redis, cola de eventos
```

Las capas externas nunca se filtran hacia las internas. Cada capa conoce √∫nicamente a la que est√° directamente por debajo.

### Esquema de colecciones MongoDB

```javascript
// Colecci√≥n: shipments
{
  _id: ObjectId,
  tracking_number: "99M-ABC12345",      // √önico, indexado
  client_id: "client_001",
  origin: {
    address: "Calle 5 #123, Ciudad de M√©xico",
    coordinates: { lat: 19.4326, lng: -99.1332 }
  },
  destination: {
    address: "Avenida Paseo #456, Puebla",
    coordinates: { lat: 19.0327, lng: -98.2064 }
  },
  package: {
    weight_kg: 5.5,
    dimensions: { length: 30, width: 20, height: 15 },
    content_description: "Electronics"
  },
  current_status: "in_transit",
  created_at: ISODate("2025-02-12T10:00:00Z"),
  updated_at: ISODate("2025-02-12T15:04:05Z"),
  // Desnormalizado para lecturas en una sola consulta
  status_history: [
    { status: "created",    timestamp: ISODate(...), source: "api",              location: null },
    { status: "picked_up",  timestamp: ISODate(...), source: "driver_app",       location: { lat: 19.4327, lng: -99.1331 } },
    { status: "in_transit", timestamp: ISODate(...), source: "driver_app",       location: { lat: 19.4326, lng: -99.1332 } }
  ]
}

// Colecci√≥n: status_events (pista de auditor√≠a)
{
  _id: ObjectId,
  tracking_number: "99M-ABC12345",
  shipment_id: ObjectId,
  status: "in_transit",
  timestamp: ISODate(...),
  source: "driver_app",
  location: { lat: 19.4326, lng: -99.1332 },
  idempotency_key: "dedup:<tracking>:<source>:<unix_ts>",
  created_at: ISODate(...)
}

// Colecci√≥n: auth_users
{
  _id: ObjectId,
  username: "client_user_001",
  password_hash: "<bcrypt>",
  role: "client",
  client_id: "client_001",
  created_at: ISODate(),
  updated_at: ISODate()
}
```

---

## Stack tecnol√≥gico

| Componente | Tecnolog√≠a | Justificaci√≥n |
|-----------|-----------|---------------|
| Lenguaje | Go 1.25 | Concurrencia nativa, bajo uso de recursos, tipado est√°tico |
| Framework web | Echo v4.12+ | Middleware ecosystem maduro, binding + validaci√≥n integrados |
| Base de datos | MongoDB 7 | Modelo de documento natural para env√≠os con historial embebido; TTL indexes para limpieza autom√°tica |
| Cache / Dedup | Redis 7 | Verificaci√≥n de duplicados O(1); TTL configurable por clave |
| Cola de eventos | Go Channels + Worker Pool | Concurrencia nativa; sin dependencias externas; escala a 1M/s con Kafka cuando sea necesario |
| Autenticaci√≥n | JWT (golang-jwt) | Stateless, escalable, est√°ndar de la industria |
| Testing | testify + k6 | Pruebas unitarias e integraci√≥n con testify; carga y E2E con k6 |
| Logging | slog (stdlib) | Logging estructurado sin dependencias externas |
| Validaci√≥n | go-playground/validator | Validaci√≥n por struct tags; integrado con el binder de Echo |
| Observabilidad | Prometheus + Grafana + cAdvisor | M√©tricas de negocio personalizadas; dashboards pre-aprovisionados |
| Documentaci√≥n API | Swagger / swaggo | OpenAPI 2.0 autogenerado desde anotaciones en el c√≥digo |
| Contenedores | Docker + Docker Compose | Entorno reproducible para desarrollo local |

---

## Decisiones de dise√±o

### 1. Per-Shipment Channel ‚Äî canal por env√≠o

**Problema:** Procesar 10K eventos por segundo de forma concurrente garantizando que los eventos del mismo env√≠o se procesen en orden.

**Soluci√≥n:** Un canal de Go independiente por `tracking_number`.

```
shipment_1: [event1] ‚Üí [event2] ‚Üí [event3]   (serial, en orden)
shipment_2: [eventA] ‚Üí [eventB]               (serial, en orden)
shipment_3: [eventX]                          (serial, en orden)

Todos los env√≠os se procesan en PARALELO entre s√≠.
Los eventos de un mismo env√≠o se procesan en ORDEN garantizado.
```

**Implementaci√≥n:**
- `map[tracking_number]chan *Event` protegido con `sync.RWMutex`
- Canal creado de forma lazy al primer evento del env√≠o
- Una goroutine worker por canal; buffer de 100 (backpressure)

**Trade-offs:**
- Ordenamiento garantizado por env√≠o
- Paralelismo total entre env√≠os distintos
- Sin dependencias externas
- El n√∫mero de env√≠os activos est√° limitado por memoria disponible (mitigado con pooling de canales inactivos)

---

### 2. Estrategia de idempotencia

**Problema:** Los eventos duplicados por reintentos o problemas de red deben manejarse de forma segura.

**Soluci√≥n:** Deduplicaci√≥n por clave compuesta en Redis + registro de auditor√≠a en MongoDB.

```go
// Clave de deduplicaci√≥n en Redis (SETEX at√≥mico)
key := fmt.Sprintf("dedup:%s:%s:%d", tracking_number, source, timestamp.Unix())

// Si SET tiene √©xito ‚Üí evento nuevo ‚Üí procesar
// Si SET falla    ‚Üí duplicado     ‚Üí descartar
```

La clave compuesta previene duplicados de la misma fuente en el mismo instante, pero permite que distintas fuentes actualicen el mismo env√≠o simult√°neamente y que la misma fuente env√≠e eventos en momentos distintos.

- Verificaci√≥n en Redis: O(1), muy baja latencia
- TTL de 1 hora previene acumulaci√≥n de memoria
- Persistencia en MongoDB para auditor√≠a y cumplimiento normativo

---

### 3. State machine ‚Äî m√°quina de estados

**Problema:** Prevenir transiciones de estado inv√°lidas (por ejemplo, `delivered ‚Üí in_warehouse`).

**Soluci√≥n:** Whitelist de transiciones permitidas definida exclusivamente en la capa de dominio.

```
created ‚Üí picked_up ‚Üí in_warehouse ‚Üí in_transit ‚Üí delivered
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí cancelled

picked_up    ‚Üí cancelled
in_warehouse ‚Üí cancelled
in_transit   ‚Üí cancelled
```

```go
var validTransitions = map[Status][]Status{
    Created:     {PickedUp, Cancelled},
    PickedUp:    {InWarehouse, Cancelled},
    InWarehouse: {InTransit, Cancelled},
    InTransit:   {Delivered},
    Delivered:   {},
    Cancelled:   {},
}
```

Esta l√≥gica reside en `internal/domain/status.go` y se prueba de forma independiente, sin mezclarla con la infraestructura.

---

### 4. Respuesta as√≠ncrona ‚Äî 202 Accepted

**Problema:** El cliente env√≠a un evento que se encola de forma as√≠ncrona. ¬øQu√© c√≥digo HTTP responder?

**Decisi√≥n:** `202 Accepted` con el evento encolado.

```http
POST /events
‚Üí HTTP/1.1 202 Accepted

{
  "event_id": "evt_xyz123",
  "status": "queued",
  "tracking_number": "99M-ABC12345",
  "message": "Event accepted for processing"
}
```

- `202` es el est√°ndar HTTP para procesamiento as√≠ncrono: indica que la solicitud fue recibida pero a√∫n no procesada.
- `200 OK` implicar√≠a procesamiento completo (incorrecto en este contexto).
- `201 Created` implicar√≠a creaci√≥n de recurso (enga√±oso).

---

### 5. Desnormalizaci√≥n del historial de estados

**Problema:** Las consultas `GET /shipments/:id` necesitan el env√≠o y su historial completo en una sola llamada.

**Decisi√≥n:** El array `status_history` se embebe directamente en el documento del env√≠o.

- Una sola consulta retorna el historial completo, sin joins.
- Actualizaci√≥n at√≥mica (ACID).
- Uso natural del modelo de documentos de MongoDB.
- Limitaci√≥n: el documento crece con el tiempo (l√≠mite de 16 MB de MongoDB). Si los historiales superan los 100K eventos por env√≠o, migrar a colecci√≥n separada con `$lookup`.

---

### 6. Autenticaci√≥n y autorizaci√≥n (RBAC)

**Implementaci√≥n:**
- Tokens JWT ‚Äî stateless, sin sesi√≥n en servidor
- Claims: `sub` (username), `role` (`client` / `admin`), `client_id`
- El middleware verifica la firma y extrae los claims en cada endpoint protegido; los handlers conf√≠an en los claims del middleware

**Roles:**
- `client`: ve √∫nicamente sus propios env√≠os, filtrado por el `client_id` del token
- `admin`: ve todos los env√≠os, sin restricci√≥n de `client_id`

**Usuarios pre-cargados en la base de datos:**

| Usuario | Contrase√±a | Rol | client_id |
|---------|-----------|-----|-----------|
| `admin_user` | `password123` | admin | ‚Äî |
| `client_user_001` | `password123` | client | `client_001` |

---

## üöÄ Inicio r√°pido

### Requisitos previos

- Go 1.21 o superior
- Docker y Docker Compose
- Make (recomendado)

### Opci√≥n A: Docker Compose (recomendado)

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd 99minutos

# 2. Levantar todos los servicios (MongoDB, Redis, API)
make docker-up

# 3. Verificar que la API responde
curl http://localhost:8080/health
# ‚Üí {"status":"ok"}
```

### Opci√≥n B: Desarrollo local (solo infraestructura en Docker)

```bash
# Levantar solo MongoDB y Redis
docker compose up -d mongo redis

# Instalar dependencias
go mod download

# Ejecutar el servidor (carga configs/.env.local)
make run
```

### Variables de entorno

Copiar la plantilla y ajustar los valores:

```bash
cp configs/.env.example configs/.env
```

```env
PORT=8080
ENV=development

MONGO_URI=mongodb://mongo:27017
MONGO_DB=shipping_system

REDIS_ADDR=redis:6378
REDIS_DB=0

JWT_SECRET=change-me-in-production

LOG_LEVEL=info
```

### Verificar la instalaci√≥n

```bash
# MongoDB
docker compose exec mongo mongosh --eval "db.version()"

# Redis
docker compose exec redis redis-cli ping
# ‚Üí PONG

# API
curl http://localhost:8080/health
# ‚Üí {"status":"ok"}
```

---

## üìñ Documentaci√≥n de la API

### Swagger UI

  <img src="./docs/swagger-documentation-shipping-tracking.png" alt="Dashboard de Grafana" width="800"/>

La API incluye una especificaci√≥n OpenAPI 2.0 generada con [swaggo](https://github.com/swaggo/swag).

| URL | Descripci√≥n |
|-----|-------------|
| `http://localhost:8080/swagger/index.html` | Swagger UI interactivo |
| `http://localhost:8080/swagger/doc.json` | Especificaci√≥n OpenAPI en JSON |

Para regenerar la especificaci√≥n tras modificar las anotaciones de los handlers:

```bash
make swagger
```

---

### Autenticaci√≥n

Todos los endpoints protegidos requieren un token JWT en el header `Authorization`:

```bash
Authorization: Bearer <token>
```

**Obtener token:**

```bash
curl -X POST http://localhost:8080/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin_user", "password": "password123"}'
```

```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "expires_in": 86400,
  "token_type": "Bearer"
}
```

---

### Endpoints

#### Crear env√≠o

```http
POST /shipments
Content-Type: application/json
Authorization: Bearer <token>

{
  "origin_address": "Calle 5 #123, Ciudad de M√©xico",
  "origin_lat": 19.4326,
  "origin_lng": -99.1332,
  "destination_address": "Avenida Paseo #456, Puebla",
  "destination_lat": 19.0327,
  "destination_lng": -98.2064,
  "weight_kg": 5.5,
  "length_cm": 30,
  "width_cm": 20,
  "height_cm": 15,
  "content_description": "Electronics",
  "client_id": "client_001"
}
```

```http
HTTP/1.1 201 Created

{
  "tracking_number": "99M-ABC12345",
  "status": "created",
  "created_at": "2025-02-12T10:00:00Z",
  "client_id": "client_001"
}
```

---

#### Consultar env√≠o

```http
GET /shipments/99M-ABC12345
Authorization: Bearer <token>
```

```http
HTTP/1.1 200 OK

{
  "tracking_number": "99M-ABC12345",
  "client_id": "client_001",
  "current_status": "in_transit",
  "origin": {
    "address": "Calle 5 #123, Ciudad de M√©xico",
    "coordinates": { "lat": 19.4326, "lng": -99.1332 }
  },
  "destination": {
    "address": "Avenida Paseo #456, Puebla",
    "coordinates": { "lat": 19.0327, "lng": -98.2064 }
  },
  "package": {
    "weight_kg": 5.5,
    "dimensions": { "length": 30, "width": 20, "height": 15 },
    "content_description": "Electronics"
  },
  "created_at": "2025-02-12T10:00:00Z",
  "updated_at": "2025-02-12T15:04:05Z",
  "status_history": [
    { "status": "created",      "timestamp": "2025-02-12T10:00:00Z", "source": "api",               "location": null },
    { "status": "picked_up",    "timestamp": "2025-02-12T10:15:00Z", "source": "driver_app",        "location": { "lat": 19.4327, "lng": -99.1331 } },
    { "status": "in_warehouse", "timestamp": "2025-02-12T12:30:00Z", "source": "warehouse_scanner", "location": null },
    { "status": "in_transit",   "timestamp": "2025-02-12T15:04:05Z", "source": "driver_app",        "location": { "lat": 19.4326, "lng": -99.1332 } }
  ]
}
```

---

#### Listar env√≠os

```http
GET /shipments?status=in_transit&limit=10&offset=0
Authorization: Bearer <token>
```

```http
HTTP/1.1 200 OK

{
  "data": [
    {
      "tracking_number": "99M-ABC12345",
      "client_id": "client_001",
      "current_status": "in_transit",
      "created_at": "2025-02-12T10:00:00Z",
      "updated_at": "2025-02-12T15:04:05Z"
    }
  ],
  "pagination": {
    "total": 45,
    "limit": 10,
    "offset": 0,
    "has_next": true
  }
}
```

**Par√°metros de consulta:**

| Par√°metro | Tipo | Descripci√≥n |
|-----------|------|-------------|
| `status` | string | `created`, `picked_up`, `in_warehouse`, `in_transit`, `delivered`, `cancelled` |
| `client_id` | string | Filtrar por cliente (solo role: `admin`) |
| `limit` | int | Resultados por p√°gina (default: 10, max: 100) |
| `offset` | int | Desplazamiento para paginaci√≥n (default: 0) |

---

#### Publicar evento

```http
POST /events
Content-Type: application/json
Authorization: Bearer <token>

{
  "tracking_number": "99M-ABC12345",
  "status": "in_transit",
  "timestamp": "2025-02-12T15:04:05Z",
  "source": "driver_app",
  "location": { "lat": 19.4326, "lng": -99.1332 }
}
```

```http
HTTP/1.1 202 Accepted

{
  "event_id": "evt_xyz123abc",
  "status": "queued",
  "tracking_number": "99M-ABC12345",
  "message": "Event accepted for processing"
}
```

---

#### Publicar lote de eventos

```http
POST /events/batch
Content-Type: application/json
Authorization: Bearer <token>

{
  "events": [
    {
      "tracking_number": "99M-ABC12345",
      "status": "in_transit",
      "timestamp": "2025-02-12T15:04:05Z",
      "source": "driver_app",
      "location": { "lat": 19.4326, "lng": -99.1332 }
    },
    {
      "tracking_number": "99M-DEF45678",
      "status": "picked_up",
      "timestamp": "2025-02-12T15:05:00Z",
      "source": "driver_app",
      "location": { "lat": 19.4327, "lng": -99.1331 }
    }
  ]
}
```

```http
HTTP/1.1 202 Accepted

{
  "received": 2,
  "queued": 2,
  "message": "All events accepted for processing"
}
```

---

#### Health check

```http
GET /health
```

```http
HTTP/1.1 200 OK

{
  "status": "ok",
  "timestamp": "2025-02-12T15:10:00Z",
  "checks": {
    "database": "ok",
    "cache": "ok",
    "event_queue": "ok"
  }
}
```

---

### C√≥digos de respuesta y errores

Todos los errores siguen este formato:

```json
{
  "error": "INVALID_TRANSITION",
  "message": "Cannot transition from 'in_transit' to 'picked_up'",
  "status_code": 400,
  "timestamp": "2025-02-12T15:10:00Z"
}
```

| C√≥digo | Significado | Ejemplo |
|--------|-------------|---------|
| 200 | OK | GET exitoso |
| 201 | Created | Env√≠o creado |
| 202 | Accepted | Evento encolado para procesamiento as√≠ncrono |
| 400 | Bad Request | JSON inv√°lido o campos faltantes |
| 401 | Unauthorized | Token ausente o inv√°lido |
| 403 | Forbidden | Cliente intentando ver env√≠os de otro cliente |
| 404 | Not Found | N√∫mero de rastreo no encontrado |
| 409 | Conflict | Transici√≥n de estado inv√°lida |
| 500 | Internal Server Error | Error inesperado del servidor |

---

## Pruebas

El proyecto cuenta con dos capas de pruebas complementarias: pruebas Go (unitarias e integraci√≥n) y pruebas black-box con k6 sobre la API en ejecuci√≥n.

### Pruebas Go

```bash
# Todas las pruebas
go test ./...

# Solo pruebas unitarias
go test ./test/unit/... -v

# Con race detector (obligatorio antes de hacer commit)
go test -race ./...

# Reporte de cobertura (HTML)
go test -coverprofile=coverage.out ./... && go tool cover -html=coverage.out -o coverage.html

# Prueba espec√≠fica por nombre
go test ./test/unit/... -run TestValidTransitions -v
```

Atajos con Make:

```bash
make test           # Ejecutar todas las pruebas
make test-race      # Con race detector
make test-coverage  # Generar reporte HTML
```

**Objetivos de cobertura:** dominio 95% ¬∑ capa de aplicaci√≥n 85% ¬∑ infraestructura 70% ¬∑ global 80%+

---

### Pruebas k6

Las pruebas k6 corren contra la API HTTP en ejecuci√≥n. Cubren autenticaci√≥n, env√≠os, eventos y el ciclo de vida completo (incluyendo idempotencia, aislamiento de RBAC, paginaci√≥n y validaci√≥n de la state machine).

**Instalar k6:** https://k6.io/docs/get-started/installation/

```bash
# Requisito: la API debe estar en ejecuci√≥n
make docker-up
```

| Archivo | Alcance | Qu√© cubre |
|---------|---------|-----------|
| `test/k6/auth.test.js` | Integraci√≥n | Login, validaci√≥n de token, credenciales incorrectas, RBAC en rutas protegidas |
| `test/k6/shipments.test.js` | Integraci√≥n | Creaci√≥n, consulta por n√∫mero de rastreo, listado con paginaci√≥n y filtros, aislamiento de RBAC |
| `test/k6/events.test.js` | Integraci√≥n | Evento √∫nico, batch, deduplicaci√≥n, transiciones inv√°lidas, casos l√≠mite de validaci√≥n |
| `test/k6/e2e.test.js` | End-to-end | Ciclo completo: crear env√≠o ‚Üí recorrer las 5 transiciones ‚Üí verificar historial en cada paso ‚Üí aislamiento RBAC |

```bash
make test-k6        # Ejecutar todas las suites k6
make test-k6-e2e    # Solo el escenario end-to-end

# Contra un entorno diferente
BASE_URL=http://staging.example.com k6 run test/k6/e2e.test.js
```

**Thresholds por defecto** (definidos en `test/k6/config.js`):

```
http_req_failed       < 1%     (tasa de error)
http_req_duration p95 < 3s     (latencia)
checks                = 100%   (todas las aserciones deben pasar)
```

---

## üìä Observabilidad

Todos los servicios de observabilidad arrancan autom√°ticamente con `make docker-up`. No se requiere configuraci√≥n adicional.

### URLs

| Servicio | URL | Credenciales |
|---------|-----|-------------|
| Grafana | `http://localhost:3000` | admin / admin |
| Prometheus | `http://localhost:9090` | ‚Äî |
| cAdvisor | `http://localhost:8081` | ‚Äî |
| M√©tricas API | `http://localhost:8080/metrics` | ‚Äî |

### Dashboard de Grafana

El dashboard `deployments/grafana/dashboards/shipping_api.json` se provisiona autom√°ticamente al arrancar. Incluye:

**Capa HTTP**
- Throughput (req/s) por m√©todo, URL y c√≥digo de estado
- Latencia p50 / p95 / p99 por endpoint
- Tasa de error (4xx + 5xx)

  <img src="./docs/dashboard-grafana-events-shippings.png" alt="Dashboard de Grafana" width="800"/>


**Pipeline de procesamiento de eventos**
- Eventos procesados/s por estado y fuente
- Duraci√≥n de procesamiento p50 / p95
- Profundidad de cola por worker
- Tasa de hits de deduplicaci√≥n
- Env√≠os creados/s

**Go runtime**
- Goroutines y OS threads (detecci√≥n de leaks)
- Duraci√≥n de GC p50 / p99

**Recursos del proceso**
- CPU (%), RSS memory (MB)
- Go heap: allocado vs reservado

  <img src="./docs/dashboard-grafana-events-resources.png" alt="Dashboard de Grafana" width="800"/>

### M√©tricas Prometheus personalizadas

| M√©trica | Tipo | Labels |
|--------|------|--------|
| `shipping_http_requests_total` | Counter | `method`, `url`, `code` |
| `shipping_http_request_duration_seconds` | Histogram | `method`, `url` |
| `shipping_events_processed_total` | Counter | `status`, `source` |
| `shipping_events_errors_total` | Counter | `reason` |
| `shipping_events_dedup_total` | Counter | `result` |
| `shipping_events_queue_depth` | Gauge | `worker_id` |
| `shipping_event_processing_duration_seconds` | Histogram | `status` |
| `shipping_shipments_created_total` | Counter | `service_type` |

---

## Escalabilidad

### Capacidad actual

```
Go Channels + 10 Workers:
‚îú‚îÄ Throughput:        ~1,000,000 eventos/segundo
‚îú‚îÄ Latencia p50:      50‚Äì100 ms
‚îú‚îÄ Latencia p99:      200‚Äì500 ms
‚îú‚îÄ Memoria (10K ev):  ~50 MB
‚îî‚îÄ CPU (10K ev/s):    ~1 n√∫cleo
```

La arquitectura actual tiene margen amplio para el target de 10K eventos/segundo.

### Fases de escalado

#### Fase 1: Actual (10K ‚Äì 100K eventos/s)

- Go channels con worker pool
- Instancia √∫nica de MongoDB con replicaci√≥n
- Redis standalone
- Instancia √∫nica de la API

Despliegue: Docker Compose o Kubernetes.

---

#### Fase 2: Alto volumen (100K ‚Äì 1M eventos/s)

Componentes a reemplazar:

1. **Cola de mensajes:** Go Channels ‚Üí Apache Kafka (topic por partici√≥n, ordenamiento por `tracking_number` como partition key)
2. **Base de datos:** MongoDB single node ‚Üí MongoDB Cluster con sharding por `tracking_number`
3. **Cache:** Redis standalone ‚Üí Redis Cluster
4. **API:** Instancia √∫nica ‚Üí M√∫ltiples instancias detr√°s de un Load Balancer

La abstracci√≥n de la cola permite cambiar la implementaci√≥n sin modificar los handlers:

```go
type EventPublisher interface {
    Publish(ctx context.Context, event *Event) error
}

var publisher EventPublisher = &ChannelPublisher{}  // Desarrollo
var publisher EventPublisher = &KafkaPublisher{}    // Producci√≥n
```

---

#### Fase 3: Escala extrema (1M+ eventos/s)

Patrones avanzados a considerar:

- **Event Sourcing:** los eventos son la fuente de verdad; las proyecciones son modelos de lectura desnormalizados
- **CQRS:** separaci√≥n de escrituras y lecturas en modelos independientes
- **Time-series DB:** rastreo de ubicaciones con ClickHouse o TimescaleDB
- **Distributed Tracing:** Jaeger con sampling del 0.1% en producci√≥n
- **Microservicios:** Shipment Service, Event Processor Service y Analytics Service comunicados v√≠a Kafka topics

---

## Trade-offs y consideraciones de producci√≥n

### 1. Consistencia eventual vs. consistencia fuerte

**Decisi√≥n adoptada:** Consistencia eventual con latencia acotada.

```
El cliente env√≠a el evento:
‚îú‚îÄ Respuesta:         202 Accepted (inmediata)
‚îî‚îÄ Procesamiento:     as√≠ncrono (~50‚Äì100 ms)
```

Se eligi√≥ consistencia eventual porque mejora el throughput, es el est√°ndar en sistemas distribuidos, el cliente puede hacer polling para confirmar el estado, y los errores se manejan con una dead-letter queue.

La alternativa sincr√≥nica ofrece mayor certeza inmediata pero a costa de mayor latencia, menor throughput y mayor complejidad en la l√≥gica de reintentos.

---

### 2. Historial embebido vs. colecci√≥n separada

**Decisi√≥n adoptada:** `status_history` embebido en el documento del env√≠o.

Ventajas: una sola consulta retorna el historial completo; actualizaci√≥n at√≥mica (ACID).  
Limitaci√≥n: el documento crece con el tiempo (l√≠mite de 16 MB en MongoDB).

Migraci√≥n futura cuando sea necesario: mover el historial a la colecci√≥n `status_events` y unir con `$lookup` en las consultas de lectura.

---

### 3. Redis para deduplicaci√≥n vs. cach√© en memoria

**Decisi√≥n adoptada:** Redis para deduplicaci√≥n + MongoDB para persistencia.

Alternativa descartada (cach√© en memoria de la aplicaci√≥n): se pierde al reiniciar, no escala a m√∫ltiples instancias y la memoria no est√° acotada.

El costo operacional de Redis es bajo y los beneficios son claros.

---

## Estructura del proyecto

```
99minutos/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ postman/                    # Colecci√≥n Postman / archivos .http
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ server/
‚îÇ       ‚îî‚îÄ‚îÄ main.go                 # Entry point: wiring de config, router y dependencias
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ .env                        # Variables de entorno locales (no versionado)
‚îÇ   ‚îî‚îÄ‚îÄ .env.example                # Plantilla de variables de entorno
‚îú‚îÄ‚îÄ deployments/
‚îÇ   ‚îî‚îÄ‚îÄ grafana/                    # Dashboards y datasources de Grafana
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ *.svg                       # Diagramas de arquitectura
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handler/                # HTTP handlers (env√≠os, eventos, health)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/             # Autenticaci√≥n / RBAC
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.go               # Registro de rutas
‚îÇ   ‚îú‚îÄ‚îÄ domain/                     # Entidades de negocio + m√°quina de estados
‚îÇ   ‚îú‚îÄ‚îÄ application/                # Casos de uso + DTOs
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ       ‚îú‚îÄ‚îÄ db/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mongo/              # Cliente y repositorio MongoDB
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ redis/              # Verificaci√≥n de idempotencia en Redis
‚îÇ       ‚îî‚îÄ‚îÄ queue/                  # Cola as√≠ncrona y worker pool
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ mongo-init.js               # Seed script de MongoDB
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ k6/                         # Pruebas de carga y E2E con k6
‚îÇ   ‚îî‚îÄ‚îÄ unit/                       # Pruebas unitarias Go
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îî‚îÄ‚îÄ README.md
```

---

## Comandos de desarrollo

```bash
make help           # Muestra todos los comandos disponibles
make build          # Compila el binario en ./bin/server
make run            # Ejecuta el servidor localmente (requiere servicios)
make test           # Ejecuta todas las pruebas
make test-race      # Ejecuta pruebas con race detector
make test-coverage  # Genera reporte de cobertura HTML
make test-k6        # Ejecuta todas las suites k6
make docker-up      # Levanta MongoDB, Redis y la API
make docker-down    # Detiene los servicios
make docker-logs    # Muestra los logs de la API
make lint           # Ejecuta el linter (golangci-lint)
make fmt            # Formatea el c√≥digo (go fmt)
make swagger        # Regenera la especificaci√≥n OpenAPI
make deps           # Descarga y ordena las dependencias
make clean          # Limpia artefactos de compilaci√≥n
```

### Flujo de trabajo t√≠pico

```bash
make docker-up      # 1. Levantar servicios
make test-race      # 2. Ejecutar pruebas con race detector
make build          # 3. Compilar
./bin/server        # 4. Ejecutar API
make docker-logs    # 5. Ver logs
make docker-down    # 6. Detener servicios
```

---

## Contribuci√≥n

1. Crear rama: `git checkout -b feature/nombre-de-la-feature`
2. Escribir pruebas primero
3. Implementar el cambio
4. Verificar: `make test-race && make lint`
5. Abrir un Pull Request con descripci√≥n del cambio y contexto

---

## Licencia

MIT License

---

Pedro Rojas Reyes ‚Äî Backend Engineer

